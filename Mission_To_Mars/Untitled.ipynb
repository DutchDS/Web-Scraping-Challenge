{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "\n",
    "import requests \n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_title: Media Get a Close-Up of NASA's Mars 2020 Rover\n",
      "news_p: The clean room at NASA's Jet Propulsion Laboratory was open to the media to see NASA's next Mars explorer before it leaves for Florida in preparation for a summertime launch.\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "### NASA Mars News ###\n",
    "#######################################################################\n",
    "\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=True)\n",
    "\n",
    "url_mars = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "browser.visit(url_mars)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Iterate through each article found\n",
    "# Tried this as well: response = requests.get(url_mars)\n",
    "# But unles JavaScript is turned of for this website, 'press release' articles show up first, not the latest one (discussed with John and Bobby)\n",
    "articles = soup.find_all('div', class_='list_text')\n",
    "\n",
    "news_title = soup.find('div', class_='content_title').text\n",
    "news_body = soup.find('div', class_='article_teaser_body').text\n",
    "\n",
    "print(\"news_title: \" + news_title)\n",
    "print(\"news_p: \" + news_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "### FEATURED IMAGE ###\n",
    "#######################################################################\n",
    "\n",
    "# URL of page to be scraped\n",
    "url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "response = requests.get(url)\n",
    "soup = bs(response.text, 'lxml')\n",
    "\n",
    "space_image = soup.article.a['data-fancybox-href']\n",
    "print(\"Largest Image found: \" + space_image)\n",
    "\n",
    "# unless the background image is needed:\n",
    "space_image_background = soup.article['style']\n",
    "\n",
    "split_str = str.split(space_image_background, ' url(\\'')\n",
    "split_str = split_str[1]\n",
    "split_str = str.split(split_str,')\\'')\n",
    "space_image_background = split_str[0]\n",
    "\n",
    "print(\"Background image found: \" + space_image_background)\n",
    "\n",
    "#This may have changed in the mean time... only a mediumsize jpg on website\n",
    "featured_image_url = 'https://www.jpl.nasa.gov' + space_image\n",
    "print(\"featured_image_url: \" + featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "### Mars Weather ###\n",
    "#######################################################################\n",
    "\n",
    "# executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "# browser = Browser('chrome', **executable_path, headless=True)# Mars Weather\n",
    "browser = init_browser()\n",
    "\n",
    "# URL of page to be scraped\n",
    "url = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "mars_weather = soup.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "print(\"mars_weather: \" + mars_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "### Mars Facts ###\n",
    "#######################################################################\n",
    "\n",
    "url = 'https://space-facts.com/mars/'\n",
    "tables = pd.read_html(url)\n",
    "facts = pd.DataFrame(tables[0])\n",
    "facts.columns = ['Mars Profile:','']\n",
    "facts = facts.set_index('Mars Profile:')\n",
    "print(\"Mars Facts:\")\n",
    "print(facts)\n",
    "\n",
    "facts.to_html(\"mars_facts.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_title: Media Get a Close-Up of NASA's Mars 2020 Rover\n",
      "news_p: The clean room at NASA's Jet Propulsion Laboratory was open to the media to see NASA's next Mars explorer before it leaves for Florida in preparation for a summertime launch.\n",
      "Largest Image found: /spaceimages/images/mediumsize/PIA14934_ip.jpg\n",
      "Background image found: /spaceimages/images/wallpaper/PIA14934-1920x1200.jpg');\n",
      "featured_image_url: https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA14934_ip.jpg\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'init_browser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f79e8074f01c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;31m# executable_path = {'executable_path': 'chromedriver.exe'}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;31m# browser = Browser('chrome', **executable_path, headless=True)# Mars Weather\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m \u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_browser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;31m# URL of page to be scraped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'init_browser' is not defined"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "### Mars Hemispheres ###\n",
    "#######################################################################\n",
    "\n",
    "# executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "# browser = Browser('chrome', **executable_path, headless=True)\n",
    "browser = init_browser()\n",
    "\n",
    "url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Find all links to clicked to obtain large image\n",
    "results = soup.find_all('a', class_='itemLink product-item')\n",
    "collection = []\n",
    "for r in results:\n",
    "    if r.h3:\n",
    "#         print(r['href'])\n",
    "        url = \"https://astrogeology.usgs.gov\" + r['href']\n",
    "        collection.append(url)\n",
    "\n",
    "# for each item in collections - find the large image by viewing the href. Then append to image list.\n",
    "\n",
    "image_list = []\n",
    "image_dict = {}\n",
    "\n",
    "for c in collection:\n",
    "    print(\"Now processing: \" + c)\n",
    "    browser.visit(c)\n",
    "    \n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    \n",
    "    image_url = soup.li.a['href']\n",
    "    title = soup.h2.text\n",
    "\n",
    "    image_dict = {'hem_titel':title , 'hem_image_url':image_url}\n",
    "    image_list.append(image_dict)\n",
    "    \n",
    "    browser.back\n",
    "\n",
    "print(\"Image List:\")\n",
    "print(image_list)\n",
    "\n",
    "mars_data = {}\n",
    "\n",
    "mars_data['news_title'] = news_title\n",
    "mars_data['news_body'] = news_body\n",
    "mars_data['featured_image_url'] = featured_image_url\n",
    "mars_data['mars_weather'] = mars_weather\n",
    "mars_data['mars_facts_url'] = 'mars_facts.html'\n",
    "mars_data['image_list'] = image_list\n",
    "\n",
    "print(\"Mars Dictionary: \")\n",
    "print(mars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
